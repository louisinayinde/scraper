# Scraper ETL Pipeline

Un pipeline ETL complet qui scrape un site web, nettoie et normalise les donnÃ©es, puis les charge dans une base de donnÃ©es PostgreSQL.

## ğŸ“‹ Vue d'ensemble

Ce projet est structurÃ© en plusieurs sprints pour apprendre progressivement :
- Web Scraping Ã©thique
- Pipeline ETL (Extract, Transform, Load)
- Gestion de base de donnÃ©es avec SQLAlchemy
- Dockerisation et orchestration
- Logs structurÃ©s

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- PostgreSQL (pour les sprints suivants)
- Docker et Docker Compose (pour les sprints suivants)

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t** (si applicable)
   ```bash
   git clone <url-du-repo>
   cd scraper
   ```

2. **CrÃ©er un environnement virtuel**
   ```bash
   python -m venv venv
   ```

3. **Activer l'environnement virtuel**
   
   Sur Windows :
   ```powershell
   .\venv\Scripts\Activate.ps1
   ```
   
   Sur Linux/Mac :
   ```bash
   source venv/bin/activate
   ```

4. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

5. **Configurer les variables d'environnement**
   ```bash
   cp .env.example .env
   ```
   
   Puis Ã©ditez le fichier `.env` avec vos valeurs de configuration (ne commitez jamais le fichier `.env` !)

## ğŸ“ Structure du projet

```
scraper/
â”œâ”€â”€ src/              # Code source principal
â”œâ”€â”€ config/           # Fichiers de configuration
â”œâ”€â”€ tests/            # Tests unitaires et d'intÃ©gration
â”œâ”€â”€ docker/           # Configuration Docker
â”œâ”€â”€ .env.example      # Exemple de variables d'environnement
â”œâ”€â”€ .gitignore        # Fichiers Ã  ignorer par Git
â”œâ”€â”€ requirements.txt  # DÃ©pendances Python
â””â”€â”€ README.md         # Ce fichier
```

## ğŸ¯ Sprints

- **Sprint 1** : Setup initial (âœ… En cours)
- **Sprint 2** : Web Scraping basique
- **Sprint 3** : Transformation des donnÃ©es
- **Sprint 4** : ModÃ©lisation et base de donnÃ©es
- **Sprint 5** : Pipeline ETL et idempotence
- **Sprint 6** : Logging et Docker

Voir `backlog.md` pour plus de dÃ©tails sur chaque sprint.

## ğŸ”§ Configuration

Les variables d'environnement sont gÃ©rÃ©es via le fichier `.env`. Copiez `.env.example` vers `.env` et configurez :

- **Base de donnÃ©es** : Connexion PostgreSQL
- **Scraping** : User-agent, dÃ©lais, timeout
- **Logs** : Niveau et format de logging

## ğŸ“š Technologies utilisÃ©es

- `httpx` : Client HTTP asynchrone
- `selectolax` : Parseur HTML rapide
- `pandas` : Manipulation et transformation de donnÃ©es
- `sqlalchemy` : ORM pour PostgreSQL
- `python-dotenv` : Gestion des variables d'environnement

## ğŸ“ Licence

Ã€ dÃ©finir selon vos besoins.

---
